---
title: "My tech stack!"
published: true
---

## 
As a Machine Learning Engineer, I work across the entire AI development lifecycle, from data preprocessing to model deployment. My tech stack is a mix of machine learning frameworks, cloud services, and software engineering tools that help me build scalable and efficient AI solutions.

## Machine Learning & Deep Learning

I rely on PyTorch for deep learning models, whether I’m working on Computer Vision or Natural Language Processing (NLP). Its flexibility and strong community support make it my go-to framework. For traditional machine learning tasks, I often use scikit-learn for feature engineering, model training, and evaluation.

When it comes to embeddings, tokenization, and transformers, I leverage Hugging Face’s Transformers. For vector databases, I integrate ChromaDB to enhance retrieval-augmented generation (RAG) applications.

## Model Deployment & MLOps
Taking a model from research to production requires robust MLOps practices. I use:

FastAPI to build and serve ML models efficiently.
Docker and Bitbucket Pipelines for containerization and CI/CD automation.
Azure OpenAI Services for integrating LLM-based solutions into enterprise applications.
MLflow for model tracking and experiment management.

## Cloud & Infrastructure

I primarily work with Azure, but I also have experience with AWS for cloud-based ML solutions. I use:

    Azure Machine Learning for training and deploying models.
    Azure Functions and serverless architectures for scalable AI services.
    Blob Storage for managing large datasets.